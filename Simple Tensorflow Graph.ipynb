{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#We will explicitly create a grapg inseat of default graph.\n",
    "graph=tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we will set our new graph as the default while we construct our mode.\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    with tf.name_scope(\"variables\"):\n",
    "        \n",
    "        #Variable to keep track of how many times the graph has been run.\n",
    "        global_step =tf.Variable(0,dtype=tf.int32, trainable=False, name=\"global_step\")\n",
    "        #Variable that keeps track of the sum of all output values over time:\n",
    "        total_output =tf.Variable(0,dtype=tf.float32, trainable=False, name=\"total_output\")\n",
    "        #Note: Reason for setting the parameter training=False is because it wont impact the model as we arent training \n",
    "        #anything.\n",
    "        \n",
    "    #Now we'll create a new core model named 'transformation' and will have \n",
    "    #seperate scope named \"input\",\"intermidiate_layer\",\"output\"\n",
    "    \n",
    "    with tf.name_scope(\"transformation\"):\n",
    "        \n",
    "        #Seperate input layer\n",
    "        with tf.name_scope(\"input\"):\n",
    "            #Create input placeholder that inputs a vector.\n",
    "            a=tf.placeholder(tf.float32,shape=[None],name=\"input_placeholder_a\")\n",
    "            #Note: shape =[None] is used in-order to accept vecotr of any length.\n",
    "        #Seperate middle layer\n",
    "        \n",
    "        with tf.name_scope(\"intermidiate_layer\"):\n",
    "            b=tf.reduce_prod(a,name=\"product_b\")\n",
    "            c=tf.reduce_sum(a,name=\"sum_c\")\n",
    "            #Note: tf.reduce_prod() will perform operation of multiplicxation on the whole vector whereas tf.multipy() \n",
    "            # will just accept 2 scalar values, hence tf.reduce_prod() is used in this case.\n",
    "            \n",
    "        #Seperate output layer\n",
    "        with tf.name_scope(\"output\"):\n",
    "            output=tf.add(b,c,name=\"output\")\n",
    "            \n",
    "        #Now we will update our global varible which were defined previously.\n",
    "        \n",
    "        with tf.name_scope(\"update\"):\n",
    "            \n",
    "            #Increment the total_output Variable by latest output.\n",
    "            update_total=total_output.assign_add(output)\n",
    "            \n",
    "            #Increment global_step variable: Will run whenever gragh runs, basically a counter.\n",
    "            increment_step= global_step.assign_add(1)\n",
    "            \n",
    "        #We will create tensorBoard summaries\n",
    "        \n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            avg=tf.div(update_total,tf.cast(increment_step,tf.float32),name=\"average\")\n",
    "            \n",
    "            #Create Summaries for output node\n",
    "            tf.summary.scalar(\"output_summary\",output) \n",
    "            tf.summary.scalar(\"total_summary\",update_total)\n",
    "            tf.summary.scalar(\"average_summary\",output)\n",
    "            \n",
    "        #Variable Initialization Operation\n",
    "        with tf.name_scope(\"global_ops\"):\n",
    "            #Initialization Op\n",
    "            init = tf.global_variables_initializer()\n",
    "            #Merge all summaries into one Operation\n",
    "            merged_summaries= tf.summary.merge_all()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running Graph \n",
    "\n",
    "sess=tf.Session(graph=graph)   \n",
    "writer =tf.summary.FileWriter('./improved_graph',graph)       #tf.train.SummaryWriter\n",
    "#Initialize all variables\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_graph(input_tensor):\n",
    "    \"\"\"\n",
    "    Helper function; runs the graph with given input tensor and saves summaries\n",
    "    \"\"\"\n",
    "    feed_dict = {a: input_tensor}\n",
    "    _,step,summary  = sess.run([output,increment_step,merged_summaries], feed_dict=feed_dict) # '_' is used in-order not ignore the sorting of output. \n",
    "    writer.add_summary(summary, global_step=step)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the graph with various inputs\n",
    "run_graph([2,8])\n",
    "run_graph([3,1,3,3])\n",
    "run_graph([8])\n",
    "run_graph([1,2,3])\n",
    "run_graph([11,4])\n",
    "run_graph([4,1])\n",
    "run_graph([7,3,1])\n",
    "run_graph([6,3])\n",
    "run_graph([0,2])\n",
    "run_graph([4,5,6])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writes the summaries to disk\n",
    "writer.flush()\n",
    "\n",
    "# Flushes the summaries to disk and closes the SummaryWriter\n",
    "writer.close()\n",
    "\n",
    "# Close the session\n",
    "sess.close()\n",
    "\n",
    "# To start TensorBoard after running this file, execute the following command:\n",
    "# $ tensorboard --logdir='./improved_graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-58-5b8bd0524c84>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-58-5b8bd0524c84>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir='./improved_graph'\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
